In recent years, the field of Sign Language Translation (SLT) and Natural Language Processing (NLP) has faced significant challenges in accurately converting sign language to text due to the complex grammar and visual nature of sign languages. Previous studies have explored various Recurrent Neural Network (RNN) hybrid models to address these issues. For instance, Xu et alinvestigated the performance of hybrid RNN architectures on SLT, highlighting the need for more effective models. This study investigates the comparative performance of Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) models in the domain of SLT. Using the 
ASLG-PC12 (English-ASL Gloss Parallel Corpus 2012) dataset, the research focuses on translating American Sign Language (ASL) glosses to English text. The methodology encompasses a comprehensive data preprocessing phase, including normalization, tokenization, and padding, followed by rigorous training, validation, and testing of both models. The significant output of this research shows that the GRU model outperforms the LSTM model in terms of BLEU-4 and ROUGE scores, with the GRU model achieving an average BLEU-4 score of 0.43 and ROUGE-1 score of 0.74. These findings underscore the potential of the GRU model to advance SLT technology, promoting more effective communication and inclusion for the deaf and hard-of-hearing communities. This advancement in SLT is particularly beneficial for improving accessibility and communication, aiding not only individuals who rely on sign language but also enhancing the broader field of NLP
